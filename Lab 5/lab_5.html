<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Laboratório 5</title>
    <link rel="icon" href="https://raw.githubusercontent.com/AndreMarques2002/processamentoVideoLabs/main/ufabc_icon.png">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/monokai-sublime.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/languages/cpp.min.js"></script>
    <script>hljs.highlightAll();</script>
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            background-image: url('https://raw.githubusercontent.com/AndreMarques2002/processamentoVideoLabs/main/Background.png');
            background-size: cover;
            color: #333;
            margin: 0;
            overflow-x: hidden;
            line-height: 1.6;
        }
        
        .video-gallery {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 20px auto;
        }

        .video-content {
            display: flex;
            flex-direction: column;
            align-items: center;
            transition: transform 0.3s ease;
        }

        .video-content:hover {
            transform: scale(1.05);
        }

        .video-content video {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        }

        .video-content h4 {
            color: black;
            margin-top: 10px;
            text-align: center;
        }
        
        ::-webkit-scrollbar {
            width: 8px;
        }

        ::-webkit-scrollbar-track {
            background: #f1f1f1;
        }

        ::-webkit-scrollbar-thumb {
            background: #aaa;
            border-radius: 4px;
        }
        
        .header {
            width: 100%;
            position: fixed;
            top: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: rgba(58, 151, 147, 0.9);
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.3);
            z-index: 10;
            transition: all 0.3s ease;
        }

        .header.shrink {
            padding: 10px;
            background-color: rgba(58, 151, 147, 1);
        }

        .logo {
            width: 100px;
            cursor: pointer;
            transition: width 0.3s ease;
        }

        .header.shrink .logo {
            width: 80px;
        }

        .menu {
            display: flex;
            gap: 25px;
        }

        .menu-item {
            text-decoration: none;
            color: white;
            font-size: 20px;
            cursor: pointer;
            transition: color 0.3s;
        }

        .menu-item:hover {
            color: #004d40;
        }

        .dropdown {
            position: relative;
            display: inline-block;
        }

        .dropdown-content {
            display: none;
            position: absolute;
            min-width: 160px;
            box-shadow: 0px 8px 16px rgba(0,0,0,0.3);
            background-color: #3a9793;
            text-align: center;
            z-index: 1;
            border-radius: 5px;
            opacity: 0;
            transition: opacity 0.3s ease, transform 0.3s ease;
            transform: translateY(-10px);
        }

        .dropdown-content a {
            color: white;
            padding: 12px 16px;
            text-decoration: none;
            display: block;
        }

        .dropdown:hover .dropdown-content {
            display: block;
            opacity: 1;
            transform: translateY(0);
        }

      	.title {
            text-align: center;
            margin-top: 150px;
            color: white;
            font-size: 2.5rem;
        }

        .section {
            margin: 20px;
            color: #222;
            background: rgba(255, 255, 255, 0.8);
            padding: 20px;
            border-radius: 8px;
        }

        .code-container {
            background-color: #23241f;
            color: #abb2bf;
            border-radius: 8px;
            padding: 0px;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .code-container code {
            color: #e06c75;
        }

        .image-gallery {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 20px auto;
        }

        .image-content {
            display: flex;
            flex-direction: column;
            align-items: center;
            transition: transform 0.3s ease;
        }

        .image-content:hover {
            transform: scale(1.05);
        }

        .image-content img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        }

        .image-content h4 {
          color: black;
          margin-top: 10px;
          text-align: center;
      	}

        .footer {
            width: 100%;
            background-color: rgba(58, 151, 147, 0.9);
            text-align: center;
            color: white;
            padding: 15px;
            font-size: 0.9rem;
            position: relative;
            bottom: 0;
        }
        .image-title {
    width: 100%;
    text-align: center;
    margin-top: 10px;
    color: black; /* Defina a cor que preferir para o título */
    font-size: 1.2rem;
}

    </style>
</head>
<body>
    <header class="header" id="header">
        <img src="https://raw.githubusercontent.com/AndreMarques2002/processamentoVideoLabs/main/ufabc_icon.png" alt="Logo UFABC" class="logo" onclick="scrollToSection('home')">
        <nav class="menu">
            <a href="../index.html" class="menu-item">Home</a>
            <div class="dropdown">
                <a class="menu-item">Trabalhos</a>
                <div class="dropdown-content">
                    <a href="../Trabalho 1/trabalho_1.html">Trabalho T1</a>
                    <a href="../Trabalho 2/trabalho_2.html">Trabalho T2</a>
                    <a href="../Trabalho 3/trabalho_3.html">Trabalho T3</a>
                    <a href="../Trabalho 4/trabalho_4.html">Trabalho T4</a>
                    <a href="../Trabalho 5/trabalho_5.html">Trabalho T5</a>
                </div>
            </div>
            <div class="dropdown">
                <a class="menu-item">Relatórios</a>
                <div class="dropdown-content">
                    <a href="../Lab 1/lab_1.html">Laboratório 1</a>
                    <a href="../Lab 2/lab_2.html">Laboratório 2</a>
                    <a href="../Lab 3/lab_3.html">Laboratório 3</a>
                    <a href="../Lab 4/lab_4.html">Laboratório 4</a>
                    <a href="lab_5.html">Laboratório 5</a>
                </div>
            </div>
        </nav>
    </header>

    <h1 class="title">Laboratório 5 - Subtração de Fundo</h1>

    <main id="home">
        <section class="section">
        <h2>Introdução</h2>
        <p class="normal-text">
           Este relatório apresenta um estudo sobre técnicas de subtração de fundo e detecção de movimento, aplicadas na área de visão computacional. O objetivo é implementar e analisar métodos de subtração de fundo, como <b>MOG2</b> e <b>KNN</b>, a fim de isolar e destacar objetos em movimento em vídeos previamente gravados e em tempo real utilizando uma webcam. A subtração de fundo é uma técnica amplamente utilizada em cenários de monitoramento e vigilância, onde se busca detectar alterações no ambiente sem a interferência do fundo estático.
        </p>
        
		<p class="normal-text">
        	Neste experimento, foram realizadas simulações com vídeos de diferentes tipos de movimento e também com imagens captadas ao vivo, a fim de comparar a eficiência dos métodos em condições distintas. Além disso, o estudo explora aplicações práticas dessas técnicas em diversas áreas, evidenciando o potencial da subtração de fundo e da detecção de movimento na análise de cenas e monitoramento de ambientes.
        </p>

        <br>

        <h2>Fundamentos básicos</h2>
        <p class="normal-text">
        	Os fundamentos deste trabalho estão baseados nas técnicas de subtração de fundo e detecção de movimento, que são amplamente utilizadas em visão computacional para identificar e rastrear objetos em movimento em uma cena. A subtração de fundo é um método que separa elementos móveis do plano de fundo estático de uma imagem ou vídeo, sendo fundamental em aplicações como monitoramento de segurança, análise de tráfego e sistemas de interação humano-computador.
        </p>
        
        <p class="normal-text">
        	A subtração de fundo é comumente realizada por algoritmos como <b>MOG2</b> e <b>KNN</b>. O <b>MOG2</b> (<i>Mixture of Gaussians</i>) utiliza uma mistura de distribuições gaussianas para modelar os pixels do plano de fundo, permitindo uma adaptação gradual às mudanças de iluminação e à variação no cenário estático. Este método é robusto em ambientes onde ocorrem pequenas variações no fundo e adapta-se a mudanças dinâmicas de forma eficaz. Já o <b>KNN</b> (<i>K-Nearest Neighbors</i>) identifica o plano de fundo com base nos pixels mais frequentes ao longo do tempo, sendo eficiente em cenários onde o plano de fundo permanece constante por períodos mais longos.
        </p>


        <br>

        <h2>Materiais e Métodos</h2>
        <h3>Lista de Materiais</h3>
            <ul>
                <li><p class="normal-text">Computador com o sistema opercional Linux 22.04 instalado</p></li>
                <li><p class="normal-text">Biblioteca OpenCV devidamente instalada</p></li>
                <li><p class="normal-text">Webcam Microsoft</p></li>
                <li><p class="normal-text">Objeto colorido</p></li>
            </ul>
        
        <br>
        
        <h2>Procedimentos Experimentais</h2>
        <p class="normal-text">
        	Os procedimentos experimentais realizados neste trabalho iniciaram-se com a configuração e execução dos métodos de subtração de fundo <b>MOG2</b> e <b>KNN</b>. Após estudar suas características, o <b>código bg_sub.cpp</b> foi configurado e executado em ambos os modos, permitindo uma observação detalhada das diferenças de desempenho entre os métodos na detecção de movimento em vídeos.
		</p>
        
        <p class="normal-text">
        	Em seguida, foi desenvolvido um programa em C++ para aplicar a subtração de fundo em vídeos previamente gravados. Esse programa gerou uma saída contendo apenas os elementos móveis, gravada em um novo vídeo, facilitando a análise visual da eficácia dos métodos para diferentes tipos de movimento.
		</p>
        
        <p class="normal-text">
        	Posteriormente, foi implementado um segundo programa em C++ para capturar imagens ao vivo usando uma webcam, mostrando o resultado da subtração de fundo. Este programa foi testado com pessoas e objetos coloridos, e foram gravados trechos desses experimentos para análise posterior.
		</p>
			
        <br>
        
        <h2>Resultados e Análises</h2>
        <h3>Parte 1</h3>
        <p class="normal-text">
        	O código <b>bg_sub.cpp</b> realiza subtração de fundo para detectar objetos em movimento em um vídeo, utilizando os métodos <b>MOG2</b> ou <b>KNN</b> do OpenCV.
        </p>

		<p class="normal-text">
        	Durante a execução, o programa processa cada quadro do vídeo, aplicando a subtração de fundo para gerar uma máscara (<b>fgMask</b>) que destaca os objetos em movimento.
      	</p>
        
        <div class="code-container">
        <pre><code class="language-cpp">
/**
 * @file bg_sub.cpp
 * @brief Background subtraction tutorial sample code
 * @author Domenico D. Bloisi
 */

#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;opencv2/imgcodecs.hpp&gt;
#include &lt;opencv2/imgproc.hpp&gt;
#include &lt;opencv2/videoio.hpp&gt;
#include &lt;opencv2/highgui.hpp&gt;
#include &lt;opencv2/video.hpp&gt;

using namespace cv;
using namespace std;

const char* params
    = "{ help h         |           | Print usage }"
      "{ input          | objlento.mp4 | Path to a video or a sequence of image }"
      "{ algo           | MOG2      | Background subtraction method (KNN, MOG2) }";

int main(int argc, char* argv[])
{
    CommandLineParser parser(argc, argv, params);
    parser.about( "This program shows how to use background subtraction methods provided by "
                  " OpenCV. You can process both videos and images.\n" );
    if (parser.has("help"))
    {
        //print help information
        parser.printMessage();
    }

    //! [create]
    //create Background Subtractor objects
    Ptr<BackgroundSubtractor> pBackSub;
    if (parser.get<String>("algo") == "MOG2")
        pBackSub = createBackgroundSubtractorMOG2();
    else
        pBackSub = createBackgroundSubtractorKNN();
    //! [create]

    //! [capture]
    VideoCapture capture( samples::findFile( parser.get<String>("input") ) );
    if (!capture.isOpened()){
        //error in opening the video input
        cerr << "Unable to open: " << parser.get<String>("input") << endl;
        return 0;
    }
    //! [capture]

	// parametros da gravação
	int frame_width = static_cast<int>(capture.get(3)); 
	int frame_height = static_cast<int>(capture.get(4));

	Size frame_size(frame_width, frame_height);
	int fps = 20;

	// criação do objeto onde será salvo o vídeo
	VideoWriter videoMask("objlento_maskMOG2.avi", VideoWriter::fourcc('M', 'J', 'P', 'G'), fps, frame_size);

    Mat frame, fgMask, bgrMask;
    while (true) {
        capture >> frame;
        if (frame.empty())
            break;

        //! [apply]
        //update the background model
        pBackSub->apply(frame, fgMask);
        //! [apply]

        //! [display_frame_number]
        //get the frame number and write it on the current frame
        rectangle(frame, cv::Point(10, 2), cv::Point(100,20),
                  cv::Scalar(255,255,255), -1);
        stringstream ss;
        ss << capture.get(CAP_PROP_POS_FRAMES);
        string frameNumberString = ss.str();
        putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
                FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));
        //! [display_frame_number]

		cvtColor(fgMask, bgrMask, COLOR_GRAY2BGR); //conversão para que seja possivel multiplexar e executar o video

        //! [show]
        //show the current frame and the fg masks
        imshow("Frame", frame);
        imshow("FG Mask", fgMask);
        videoMask.write(bgrMask); //salva o video
        //! [show]

        //get the input from the keyboard
        int keyboard = waitKey(30);
        if (keyboard == 'q' || keyboard == 27)
            break;
    }

    return 0;
}
		</code></pre>
      	</div>

        <p class="normal-text">
        	A partir do código acima, utilizou-se o vídeo com o objeto movimentando-se lentamente, gravado no Laboratório 1.
      	</p>
        
        <div class="video-gallery">
          <div class="video-content">
              <video controls>
                  <source src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%205/Parte%201/objlento_maskKNN.mp4" type="video/mp4">
                  Seu navegador não suporta o vídeo.
              </video>
              <h4 class="image-title">Gravação do objeto lento com modo KNN</h4>
          </div>
          <div class="video-content">
              <video controls>
                  <source src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%205/Parte%201/objlento_maskMOG2.mp4" type="video/mp4">
                  Seu navegador não suporta o vídeo.
              </video>
              <h4 class="image-title">Gravação do objeto lento com modo MOG2</h4>
          </div>
        </div>
        
        <p class="normal-text">
        	O mesmo procedimento foi realizado com a gravação do objeto em movimento lento.
      	</p>
        
        <div class="video-gallery">
          <div class="video-content">
              <video controls>
                  <source src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%205/Parte%201/objrapido_maskKNN.mp4" type="video/mp4">
                  Seu navegador não suporta o vídeo.
              </video>
              <h4 class="image-title">Gravação do objeto rapido com modo KNN</h4>
          </div>
          <div class="video-content">
              <video controls>
                  <source src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%205/Parte%201/objrapido_maskMOG2.mp4" type="video/mp4">
                  Seu navegador não suporta o vídeo.
              </video>
              <h4 class="image-title">Gravação do objeto rapido com modo MOG2</h4>
          </div>
        </div>
        
        
        <br>
        
        <h3>Parte 2</h3>
        <p class="normal-text">
        	O código abaixo realiza a subtração de fundo em um vídeo de entrada usando os métodos <b>MOG2</b> ou <b>KNN</b> da biblioteca OpenCV, permitindo detectar e destacar objetos em movimento.
        </p>
        
        <div class="code-container">
        <pre><code class="language-cpp"> 
/**
 * @file bg_sub.cpp
 * @brief Background subtraction tutorial sample code
 * @author Domenico D. Bloisi
 */

#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include &lt;opencv2/imgcodecs.hpp&gt;
#include &lt;opencv2/imgproc.hpp&gt;
#include &lt;opencv2/videoio.hpp&gt;
#include &lt;opencv2/highgui.hpp&gt;
#include &lt;opencv2/video.hpp&gt;

using namespace cv;
using namespace std;

const char* params
    = "{ help h         |           | Print usage }"
      /*"{ input          | objlento.mp4 | Path to a video or a sequence of image }"*/ //Ignorado pois usamos webcam
      "{ algo           | KNN      | Background subtraction method (KNN, MOG2) }";

int main(int argc, char* argv[])
{
    CommandLineParser parser(argc, argv, params);
    parser.about( "This program shows how to use background subtraction methods provided by "
                  " OpenCV. You can process both videos and images.\n" );
    if (parser.has("help"))
    {
        //print help information
        parser.printMessage();
    }

    //! [create]
    //create Background Subtractor objects
    Ptr<BackgroundSubtractor> pBackSub;
    if (parser.get<String>("algo") == "MOG2")
        pBackSub = createBackgroundSubtractorMOG2();
    else
        pBackSub = createBackgroundSubtractorKNN();
    //! [create]

    //! [capture]
    VideoCapture capture(0); //alterado para ler webcam
    if (!capture.isOpened()){
        //error in opening the video input
        cerr << "Unable to open: " << parser.get<String>("input") << endl;
        return 0;
    }
    //! [capture]

	// parametros da gravação
	int frame_width = static_cast<int>(capture.get(3)); 
	int frame_height = static_cast<int>(capture.get(4));

	Size frame_size(frame_width, frame_height);
	int fps = 20;

	// criação do objeto onde será salvo o vídeo
	VideoWriter videoMask("pessoa_maskKNN.avi", VideoWriter::fourcc('M', 'J', 'P', 'G'), fps, frame_size);

    Mat frame, fgMask, bgrMask;
    while (true) {
        capture >> frame;
        if (frame.empty())
            break;

        //! [apply]
        //update the background model
        pBackSub->apply(frame, fgMask);
        //! [apply]

        //! [display_frame_number]
        //get the frame number and write it on the current frame
        rectangle(frame, cv::Point(10, 2), cv::Point(100,20),
                  cv::Scalar(255,255,255), -1);
        stringstream ss;
        ss << capture.get(CAP_PROP_POS_FRAMES);
        string frameNumberString = ss.str();
        putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
                FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));
        //! [display_frame_number]

		cvtColor(fgMask, bgrMask, COLOR_GRAY2BGR); //conversão para que seja possivel multiplexar e executar o video

        //! [show]
        //show the current frame and the fg masks
        imshow("Frame", frame);
        imshow("FG Mask", fgMask);
        videoMask.write(bgrMask); //salva o video
        //! [show]

        //get the input from the keyboard
        int keyboard = waitKey(30);
        if (keyboard == 'q' || keyboard == 27)
            break;
    }

    return 0;
}
		</code></pre>
      	</div>
        
        <p class="normal-text">
        	Utilizando-se um objeto colorido, obteve-se o resultado abaixo com os modos <b>KNN</b> e <b>MOG2</b>.
      	</p>
        
        <div class="video-gallery">
          <div class="video-content">
              <video controls>
                  <source src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%205/Parte%202/obj_maskKNN.mp4" type="video/mp4">
                  Seu navegador não suporta o vídeo.
              </video>
              <h4 class="image-title">Gravação do objeto colorido com modo KNN</h4>
          </div>
          <div class="video-content">
              <video controls>
                  <source src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%205/Parte%202/obj_maskMOG2.mp4" type="video/mp4">
                  Seu navegador não suporta o vídeo.
              </video>
              <h4 class="image-title">Gravação do objeto colorido com modo MOG2</h4>
          </div>
        </div>

        <p class="normal-text">
        	Por fim, foi realizada uma gravação com os integrantes do grupo em ambos os modos.
      	</p>
        
        <div class="video-gallery">
          <div class="video-content">
              <video controls>
                  <source src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%205/Parte%202/pessoa_maskKNN.mp4" type="video/mp4">
                  Seu navegador não suporta o vídeo.
              </video>
              <h4 class="image-title">Gravação do grupo com modo KNN</h4>
          </div>
          <div class="video-content">
              <video controls>
                  <source src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%205/Parte%202/pessoa_maskMOG2.mp4" type="video/mp4">
                  Seu navegador não suporta o vídeo.
              </video>
              <h4 class="image-title">Gravação do grupo com modo MOG2</h4>
          </div>
        </div>

        <br>
        
        <h3>Parte 3</h3>
        <p class="normal-text">
        	O algoritmo de subtração de fundo possui diversas aplicações. No trabalho que está sendo desenvolvido pelo grupo, que consiste na extração de informações de placas veiculares, este recurso podewria ser implementado.
        </p>
        
        <p class="normal-text">
        	Neste contexto, através dos modos <b>KNN</b> e <b>MOG2</b>, com o auxílio da webcam, gravações do tráfego poderiam ser feitas e, a partir disso, os veículos em movimento seria captados, removendo-se os demais elementos do frame. Isso facilitaria a identificação das placas e, por conseguinte, dos carqacteres nelas presentes.
        </p>
        
        <br>

        <h2>Conclusões e Comentários Finais</h2>
        <p class="normal-text">
        	Com o experimento, pode-se concluir que os métodos de subtração de fundo <b>MOG2</b> e <b>KNN</b> são eficazes para a detecção de movimento em vídeos, destacando objetos móveis com precisão. Ambos os métodos foram aplicados com sucesso tanto em vídeos gravados quanto em imagens capturadas ao vivo, demonstrando sua aplicabilidade em monitoramento e análise de cenas dinâmicas. O estudo evidenciou ainda que a escolha entre os métodos pode ser feita conforme as características do ambiente, permitindo adaptações para diferentes contextos de uso.
	</p>
        
    	</div>
    </section>
    </main>

    <footer class="footer">
        <p>&copy; 2024 PROCESSAMENTO DE VÍDEO - UFABC</p>
    </footer>

    <script>
        function scrollToSection(sectionId) {
            document.getElementById(sectionId).scrollIntoView({ behavior: 'smooth' });
        }

        window.addEventListener('scroll', () => {
            const header = document.getElementById('header');
            if (window.scrollY > 50) {
                header.classList.add('shrink');
            } else {
                header.classList.remove('shrink');
            }
        });
    </script>
</body>
</html>
