<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Laboratório 7</title>
    <link rel="icon" href="https://raw.githubusercontent.com/AndreMarques2002/processamentoVideoLabs/main/ufabc_icon.png">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/monokai-sublime.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/languages/cpp.min.js"></script>
    <script>hljs.highlightAll();</script>
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            background-image: url('https://raw.githubusercontent.com/AndreMarques2002/processamentoVideoLabs/main/Background.png');
            background-size: cover;
            color: #333;
            margin: 0;
            overflow-x: hidden;
            line-height: 1.6;
        }
        
        .video-gallery {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 20px auto;
        }

        .video-content {
            display: flex;
            flex-direction: column;
            align-items: center;
            transition: transform 0.3s ease;
        }

        .video-content:hover {
            transform: scale(1.05);
        }

        .video-content video {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        }

        .video-content h4 {
            color: black;
            margin-top: 10px;
            text-align: center;
        }
        
        ::-webkit-scrollbar {
            width: 8px;
        }

        ::-webkit-scrollbar-track {
            background: #f1f1f1;
        }

        ::-webkit-scrollbar-thumb {
            background: #aaa;
            border-radius: 4px;
        }
        
        .header {
            width: 100%;
            position: fixed;
            top: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: rgba(58, 151, 147, 0.9);
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.3);
            z-index: 10;
            transition: all 0.3s ease;
        }

        .header.shrink {
            padding: 10px;
            background-color: rgba(58, 151, 147, 1);
        }

        .logo {
            width: 100px;
            cursor: pointer;
            transition: width 0.3s ease;
        }

        .header.shrink .logo {
            width: 80px;
        }

        .menu {
            display: flex;
            gap: 25px;
        }

        .menu-item {
            text-decoration: none;
            color: white;
            font-size: 20px;
            cursor: pointer;
            transition: color 0.3s;
        }

        .menu-item:hover {
            color: #004d40;
        }

        .dropdown {
            position: relative;
            display: inline-block;
        }

        .dropdown-content {
            display: none;
            position: absolute;
            min-width: 160px;
            box-shadow: 0px 8px 16px rgba(0,0,0,0.3);
            background-color: #3a9793;
            text-align: center;
            z-index: 1;
            border-radius: 5px;
            opacity: 0;
            transition: opacity 0.3s ease, transform 0.3s ease;
            transform: translateY(-10px);
        }

        .dropdown-content a {
            color: white;
            padding: 12px 16px;
            text-decoration: none;
            display: block;
        }

        .dropdown:hover .dropdown-content {
            display: block;
            opacity: 1;
            transform: translateY(0);
        }

      	.title {
            text-align: center;
            margin-top: 150px;
            color: white;
            font-size: 2.5rem;
        }

        .section {
            margin: 20px;
            color: #222;
            background: rgba(255, 255, 255, 0.8);
            padding: 20px;
            border-radius: 8px;
        }

        .code-container {
            background-color: #23241f;
            color: #abb2bf;
            border-radius: 8px;
            padding: 0px;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .code-container code {
            color: #e06c75;
        }

        .image-gallery {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 20px auto;
        }

        .image-content {
            display: flex;
            flex-direction: column;
            align-items: center;
            transition: transform 0.3s ease;
        }

        .image-content:hover {
            transform: scale(1.05);
        }

        .image-content img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        }

        .image-content h4 {
          color: black;
          margin-top: 10px;
          text-align: center;
      	}

        .footer {
            width: 100%;
            background-color: rgba(58, 151, 147, 0.9);
            text-align: center;
            color: white;
            padding: 15px;
            font-size: 0.9rem;
            position: relative;
            bottom: 0;
        }
        .image-title {
    width: 100%;
    text-align: center;
    margin-top: 10px;
    color: black;
    font-size: 1.2rem;
}

    </style>
</head>
<body>
    <header class="header" id="header">
        <img src="https://raw.githubusercontent.com/AndreMarques2002/processamentoVideoLabs/main/ufabc_icon.png" alt="Logo UFABC" class="logo" onclick="scrollToSection('home')">
        <nav class="menu">
            <a href="../index.html" class="menu-item">Home</a>
            <div class="dropdown">
                <a class="menu-item">Trabalhos</a>
                <div class="dropdown-content">
                    <a href="../Trabalho 1/trabalho_1.html">Trabalho T1</a>
                    <a href="../Trabalho 2/trabalho_2.html">Trabalho T2</a>
                    <a href="../Trabalho 3/trabalho_3.html">Trabalho T3</a>
                    <a href="../Trabalho 4/trabalho_4.html">Trabalho T4</a>
                    <a href="../Trabalho 5/trabalho_5.html">Trabalho T5</a>
                </div>
            </div>
            <div class="dropdown">
                <a class="menu-item">Relatórios</a>
                <div class="dropdown-content">
                    <a href="../Lab 1/lab_1.html">Laboratório 1</a>
                    <a href="../Lab 2/lab_2.html">Laboratório 2</a>
                    <a href="../Lab 3/lab_3.html">Laboratório 3</a>
                    <a href="../Lab 4/lab_4.html">Laboratório 4</a>
                    <a href="../Lab 5/lab_5.html">Laboratório 5</a>
                    <a href="lab_7.html">Laboratório 7</a>
                </div>
            </div>
        </nav>
    </header>

    <h1 class="title">Laboratório 7 - Detecção de Objetos</h1>

    <main id="home">
        <section class="section">
        <h2>Introdução</h2>
        <p class="normal-text">
           A detecção de objetos utilizando classificadores em cascata baseados em características Haar é um método eficaz proposto por Paul Viola e Michael Jones em 2001. Este método de aprendizado de máquina envolve o treinamento de uma função 
		em cascata com muitas imagens positivas, no nosso caso imagens com rostos, e negativas, sem rostos. O objetivo é detectar faces em novas imagens.
        </p>

        <br>

        <h2>Fundamentos básicos</h2>
        <p class="normal-text">
        	Inicialmente, o algoritmo requer muitas imagens positivas (rostos) e negativas (sem rostos) para treinar o classificador. As características Haar, semelhantes aos kernels de convolução, são extraídas das imagens. Cada característica é um valor único obtido pela subtração da soma dos pixels sob o retângulo branco da soma dos pixels sob o retângulo preto.
	</p>
	<p class="normal-text">
		Para calcular todas as características possíveis, são utilizadas todas as possíveis localizações e tamanhos de cada kernel. A imagem integral é introduzida para reduzir os cálculos necessários, envolvendo apenas quatro pixels por operação. 
		No entanto, muitas dessas características são irrelevantes. A seleção das melhores características é feita pelo Adaboost, que ajusta pesos e recalcula taxas de erro até alcançar a acurácia desejada ou encontrar o número necessário de 
		características.
        </p>

        <br>

        <h2>Materiais e Métodos</h2>
        <h3>Lista de Materiais</h3>
            <ul>
                <li><p class="normal-text">Computador com o sistema opercional Linux 22.04 instalado</p></li>
                <li><p class="normal-text">Biblioteca OpenCV devidamente instalada</p></li>
                <li><p class="normal-text">Webcam Microsoft</p></li>
            </ul>
        
        <br>
        
        <h2>Procedimentos Experimentais</h2>
        <p class="normal-text">
        	Os procedimentos experimentais realizados neste trabalho iniciaram-se com a configuração e execução do método de detecção em casacata Haar. Após estudar suas características, os códigos LAB07_parte1.cpp e 
		LAB07_parte2.cpp foram configurados e executados nos diferentes modelos, permitindo uma observação detalhada das diferenças de desempenho entre os métodos na detecção.
	</p>
			
        <br>
        
        <h2>Resultados e Análises</h2>
        <h3>Parte 1</h3>
        <p class="normal-text">
        	Para a imagem do grupo, a melhor combinação encontrada para detecção dos rostos e dos olhos foi o modelo haarcascade_frontalface_alt.xml para os rostos e o modelo  haarcascade_righteye_2splits.xml para os olhos.
        </p>
        
        <div class="code-container">
        <pre><code class="language-cpp"> 
#include "opencv2/objdetect.hpp"
#include "opencv2/highgui.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/videoio.hpp"
#include &lt;opencv2/core.hpp&gt;
#include &lt;opencv2/imgcodecs.hpp&gt;
#include &lt;iostream&gt;
 
using namespace std;
using namespace cv;

void detectAndDisplay( Mat frame );
 
CascadeClassifier face_cascade;
CascadeClassifier eyes_cascade;
 
int main()
{
 
    String face_cascade_name = samples::findFile("haarcascade_frontalface_alt.xml");
    String eyes_cascade_name = samples::findFile("haarcascade_righteye_2splits.xml"); 
 
    if( !face_cascade.load( face_cascade_name ) )
    {
        cout << "--(!)Error loading face cascade\n";
        return -1;
    };
    if( !eyes_cascade.load( eyes_cascade_name ) )
    {
        cout << "--(!)Error loading eyes cascade\n";
        return -1;
    };
     
	
    Mat frame = imread("foto_grupo.jpeg", IMREAD_COLOR);
    
    if( frame.empty() )
    {
       printf("Sem imagem");
       return 0;
	}
 
     //-- 3. Apply the classifier to the frame
     
     detectAndDisplay( frame );
	
     if( waitKey(0) == 27 )
     {
       return 0; // escape
     }
	  
	 int s = waitKey(0);
	 if( s == 's')
	 {
		 imwrite("Lab07_parte1.png", frame);
	 }
    
     return 0;
}

void detectAndDisplay(Mat frame )
{
    Mat frame_gray;
    cvtColor( frame, frame_gray, COLOR_BGR2GRAY );
    equalizeHist( frame_gray, frame_gray );
 
    //-- Detect faces
    std::vector<Rect> faces;
    face_cascade.detectMultiScale( frame_gray, faces );
 
    for ( size_t i = 0; i < faces.size(); i++ )
    {
        Point center( faces[i].x + faces[i].width/2, faces[i].y + faces[i].height/2 );
        ellipse( frame, center, Size( faces[i].width/2, faces[i].height/2 ), 0, 0, 360, Scalar( 255, 0, 255 ), 4 ); 
 
        Mat faceROI = frame_gray( faces[i] );
 
        //-- In each face, detect eyes
        std::vector<Rect> eyes;
        eyes_cascade.detectMultiScale( faceROI, eyes );
 
        for ( size_t j = 0; j < eyes.size(); j++ )
        {
            Point eye_center( faces[i].x + eyes[j].x + eyes[j].width/2, faces[i].y + eyes[j].y + eyes[j].height/2 );
            int radius = cvRound( (eyes[j].width + eyes[j].height)*0.25 );
            circle( frame, eye_center, radius, Scalar( 255, 0, 0 ), 4 );
        }
    }
	
    imshow("Display Image./LAB07",frame);
}
		</code></pre>
      	</div>
        
        <p class="normal-text">
        	<b>Rostos: </b> Foram testados todos os modelos disponibilizados no github, exceto o selecionado e indicado acima, dos demais parte não reconheceu os rostos e, dos que conseguiram reconhecer, acabaram computando também alguma parte da roupa ou do fundo, poluindo a imagem. Um exemplo desse caso pode ser visto na imagem abaixo em que utilizamos o modelo haarcascade_profileface.xml. Além disso, nenhum dos modelos conseguiu detectar o rosto de um dos integrantes, provavelmente devido a foto estar cortada. 
		</p>
        
        <section class="image-gallery">
          <div class="image-content">
              <img src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%207/Parte%201/foto_grupo.jpeg">
              <h4 class="image-title">Imagem original do grupo (à esquerda, o integrante não reconhecido pelos modelos de detecção de imagem)</h4>
          </div>
          <div class="image-content">
              <img src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%207/Parte%201/L07P1_grupo_ExemploRuim.png">
              <h4 class="image-title">Modelos haarcascade_profileface.xml e haarcascade_righteye_2splits.xml aplicados na imagem do grupo (rostos não detectados)
</h4>
          </div>
        </section>
        
        
		<p class="normal-text">
        	<b>Olhos: </b>Realizou-se testes com os demais modelos disponíveis mas em alguns casos apenas um dos olhos era detectado (vide exemplo abaixo em que utilizamos o modelo padrão do programa: haarcascade_eye_tree_eyeglasses). Para os testes, mantivemos o modelo haarcascade_frontalface_alt.xml para os rostos.
		</p>
        
        
        <section class="image-gallery">
          <div class="image-content">
              <img src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%207/Parte%201/L07P1_grupo_caolho.png">
              <h4 class="image-title">Modelos haarcascade_frontalface_alt.xml e haarcascade_eye_tree_eyeglasses.xml aplicados na imagem do grupo (apenas o olho esquerdo dos integrantes foi detectado)</h4>
          </div>
        </section>
        
        <p class="normal-text">
        	O melhor resultado foi obtido com o modelo haarcascade_righteye_2splits que produziu a seguinte imagem:
        </p>
        
        <section class="image-gallery">
          <div class="image-content">
              <img src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%207/Parte%201/L07P1_grupo.png">
              <h4 class="image-title">Modelo haarcascade_righteye_2splits</h4>
          </div>
        </section>
        
        <p class="normal-text">
        	Partindo para a imagem dos avatares, ao testarmos os filtros que tiveram melhores resultados para a imagem do grupo, não obtemos os mesmos resultados positivos. Nesse caso a detecção falha em reconhecer os rostos e olhos e identifica somente uma parte do uniforme de um dos avatares:
        </p>
        
        <section class="image-gallery">
          <div class="image-content">
              <img src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%207/Parte%201/L07P1_avatar_FiltrosGrupo.png">
              <h4 class="image-title">Imagem dos avatares utilizando os modelos que apresentaram os melhores resultados na imagem do grupo</h4>
          </div>
        </section>
        
        <p class="normal-text">
        	Testando todos os demais modelos, encontramos um resultado um pouco mais promissor utilizando o modelo haarcascade_frontalface_default.xml em que a detecção ao menos se posicionou mais perto do rosto do avatar, ainda que não o tenha reconhecido completamente. Esse, no entanto, foi o melhor resultado obtido após todos os testes:
        </p>
        
        <section class="image-gallery">
          <div class="image-content">
              <img src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%207/Parte%201/Lab07_parte1_modeloDefault.png">
              <h4 class="image-title">Imagem utilizando o modelo haarcascade_frontalface_default.xml para os rostos</h4>
          </div>
        </section>
        
        <p class="normal-text">
        	Todos os demais modelos resultaram na imagem vazia sem nenhuma detecção. Um exemplo disso pode ser visto na imagem abaixo em que o modelo haarcascade_frontalcatface_extended.xml foi utilizado:
        </p>
        
        <section class="image-gallery">
          <div class="image-content">
              <img src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%207/Parte%201/L07P1_avatar_OutrosModelos.png">
              <h4 class="image-title">Imagem utilizando o modelo haarcascade_frontalcatface_extended.xml</h4>
          </div>
        </section>
        
        
        <h3>Parte 2</h3>
        <p class="normal-text">
        	Para a parte 2 foram necessárias modificações mínimas no código original. Adicionamos uma variável chamada “frame_limpo” que armazena a imagem da webcam antes que esta passe pelo detector. Também antes do detector, essa imagem limpa é exibida em uma nova janela. Além disso, adicionamos a condição de ao pressionar a tecla ‘s’ o programa registra a imagem da webcam com o detector ativo. Ademais, o programa permaneceu igual ao original.
        </p>
        
        <div class="code-container">
        <pre><code class="language-cpp"> 
#include "opencv2/objdetect.hpp"
#include "opencv2/highgui.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/videoio.hpp"
#include &lt;iostream&gt;
 
using namespace std;
using namespace cv;
 
void detectAndDisplay( Mat frame );
 
CascadeClassifier face_cascade;
CascadeClassifier eyes_cascade;
 
int main( int argc, const char** argv )
{
    CommandLineParser parser(argc, argv,
                             "{help h||}"
                             "{camera|0|Camera device number.}");
 
    parser.about( "\nThis program demonstrates using the cv::CascadeClassifier class to detect objects (Face + eyes) in a video stream.\n"
                  "You can use Haar or LBP features.\n\n" );
    parser.printMessage();
 
    String face_cascade_name = samples::findFile("haarcascade_frontalface_alt.xml");
    String eyes_cascade_name = samples::findFile("haarcascade_righteye_2splits.xml");
 
    //-- 1. Load the cascades
    if( !face_cascade.load( face_cascade_name ) )
    {
        cout << "--(!)Error loading face cascade\n";
        return -1;
    };
    if( !eyes_cascade.load( eyes_cascade_name ) )
    {
        cout << "--(!)Error loading eyes cascade\n";
        return -1;
    };
 
    int camera_device = parser.get<int>("camera");
    VideoCapture capture;
    //-- 2. Read the video stream
    capture.open( camera_device );
    if ( ! capture.isOpened() )
    {
        cout << "--(!)Error opening video capture\n";
        return -1;
    }
 
    Mat frame, frame_limpo;
    while ( capture.read(frame) )
    {
        if( frame.empty() )
        {
            cout << "--(!) No captured frame -- Break!\n";
            break;
        }
		
		frame_limpo = frame;
		imshow("Imagem sem detector", frame_limpo);
		
        //-- 3. Apply the classifier to the frame
        detectAndDisplay( frame );
        
        int s = waitKey(1);
		if( s == 's')
		{
			imwrite("L7P2_ModeloOn.png", frame);
		}
		
		int q = waitKey(1);
        if( q == 'q')
        {
            break; // escape
        }
    }
    return 0;
}
 
void detectAndDisplay( Mat frame )
{
    Mat frame_gray;
    cvtColor( frame, frame_gray, COLOR_BGR2GRAY );
    equalizeHist( frame_gray, frame_gray );
 
    //-- Detect faces
    std::vector<Rect> faces;
    face_cascade.detectMultiScale( frame_gray, faces );
 
    for ( size_t i = 0; i < faces.size(); i++ )
    {
        Point center( faces[i].x + faces[i].width/2, faces[i].y + faces[i].height/2 );
        ellipse( frame, center, Size( faces[i].width/2, faces[i].height/2 ), 0, 0, 360, Scalar( 255, 0, 255 ), 4 );
 
        Mat faceROI = frame_gray( faces[i] );
 
        //-- In each face, detect eyes
        std::vector<Rect> eyes;
        eyes_cascade.detectMultiScale( faceROI, eyes );
 
        for ( size_t j = 0; j < eyes.size(); j++ )
        {
            Point eye_center( faces[i].x + eyes[j].x + eyes[j].width/2, faces[i].y + eyes[j].y + eyes[j].height/2 );
            int radius = cvRound( (eyes[j].width + eyes[j].height)*0.25 );
            circle( frame, eye_center, radius, Scalar( 255, 0, 0 ), 4 );
        }
    }
 
    //-- Show what you got
    imshow( "Capture - Face detection", frame );
}

		</code></pre>
      	</div>
        
        <p class="normal-text">
        	A partir do código, obteve-se o resultado abaixo.
		</p>
    
    	<section class="image-gallery">
          <div class="image-content">
              <img src="https://raw.githubusercontent.com/AndreMarques2002/LabProcessamentoVideo/main/Lab%207/Parte%202/L7P2_ModeloOn.png">
          </div>
        </section>
        
        
        <br>

        <h2>Conclusões e Comentários Finais</h2>
        <p class="normal-text">
        	O método de detecção de objetos utilizando classificadores em cascata baseados em características Haar é um avanço significativo na área de detecção de faces. Os experimentos realizados demonstraram a eficácia do método, 
		com a configuração dos códigos LAB07_parte1.cpp e LAB07_parte2.cpp permitindo uma análise detalhada das diferenças de desempenho entre os métodos de detecção. Apesar de alguns desafios, como a não detecção de rostos em 
		imagens cortadas ou a detecção incompleta de olhos, os resultados mostraram que modelos específicos como haarcascade_frontalface_alt.xml e haarcascade_righteye_2splits.xml obtiveram os melhores desempenhos.
	</p>
	<p class="normal-text">
		A utilização de modelos em cascata e a modificação mínima necessária no código original para adaptar a detecção em tempo real com a webcam, ressaltam a flexibilidade e adaptabilidade do método. As melhorias sugeridas e 
		implementadas, como o armazenamento da imagem "frame_limpo" e a captura de imagens com o detector ativo, mostram o potencial para aplicações práticas e futuras melhorias no sistema.
	</p>
	<p class="normal-text">
		Em suma, o método proposto é uma ferramenta poderosa e versátil para a detecção de faces, capaz de ser aprimorado e adaptado conforme as necessidades específicas de diferentes projetos e aplicações.
	</p>
    
    	</div>
    </section>
    </main>
    
    <footer class="footer">
        <p>&copy; 2024 PROCESSAMENTO DE VÍDEO - UFABC</p>
    </footer>

    <script>
        function scrollToSection(sectionId) {
            document.getElementById(sectionId).scrollIntoView({ behavior: 'smooth' });
        }

        window.addEventListener('scroll', () => {
            const header = document.getElementById('header');
            if (window.scrollY > 50) {
                header.classList.add('shrink');
            } else {
                header.classList.remove('shrink');
            }
        });
    </script>
</body>
</html>
